{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install indic-nlp-library"
      ],
      "metadata": {
        "id": "kkRxTuOUPObc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-07RUesRTRH",
        "outputId": "b1b10d4b-0849-4ec6-aa0e-48e8d0e95e70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "torchtext.disable_torchtext_deprecation_warning()\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch.nn.functional import one_hot\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "metadata": {
        "id": "3JRt9DgoIzVC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_filepath = \"/content/drive/MyDrive/IITB.en-hi.en\"\n",
        "hi_filepath = \"/content/drive/MyDrive/IITB.en-hi.hi\"\n",
        "\n",
        "with open(en_filepath, \"r\", encoding='utf-8') as f:\n",
        "  english_data = f.readlines()\n",
        "\n",
        "with open(hi_filepath, \"r\", encoding='utf-8') as f:\n",
        "  hindi_data = f.readlines()"
      ],
      "metadata": {
        "id": "SYiAWp0p7CHh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req_hindi = hindi_data[212929:267939]\n",
        "req_english = english_data[212929:267939]\n",
        "data = {\"english_txt\":req_english,\"hindi_txt\":req_hindi}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "vHq9uIt47tMw"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "A8y1hR9YHvuU",
        "outputId": "942e1fed-c0ed-4b29-b2b2-b5dc946e9b98"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         english_txt                         hindi_txt\n",
              "8894    Hide process para _ meters\\n  छुपाएँ process अनुच्छेद मीटर्स\\n\n",
              "99246                      N _ one\\n                  कुछनहीं (_ o) \\n\n",
              "74559                        Reply\\n                            जवाब\\n\n",
              "195764            Download Manager\\n     डाउनलोड संख्याः trust level\\n\n",
              "193870                    % 1 -% 2\\n                       % 1 से% 2\\n\n",
              "121283                       Scope\\n                              घर\\n\n",
              "217939                         CNY\\n                             CNY\\n\n",
              "67198       STARTTLS not supported\\n         STARTTLS समर्थित नहीं. \\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc80dcd8-7d2b-46a4-abb2-12039b78456a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_txt</th>\n",
              "      <th>hindi_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8894</th>\n",
              "      <td>Hide process para _ meters\\n</td>\n",
              "      <td>छुपाएँ process अनुच्छेद मीटर्स\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99246</th>\n",
              "      <td>N _ one\\n</td>\n",
              "      <td>कुछनहीं (_ o) \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74559</th>\n",
              "      <td>Reply\\n</td>\n",
              "      <td>जवाब\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195764</th>\n",
              "      <td>Download Manager\\n</td>\n",
              "      <td>डाउनलोड संख्याः trust level\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193870</th>\n",
              "      <td>% 1 -% 2\\n</td>\n",
              "      <td>% 1 से% 2\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121283</th>\n",
              "      <td>Scope\\n</td>\n",
              "      <td>घर\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217939</th>\n",
              "      <td>CNY\\n</td>\n",
              "      <td>CNY\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67198</th>\n",
              "      <td>STARTTLS not supported\\n</td>\n",
              "      <td>STARTTLS समर्थित नहीं. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc80dcd8-7d2b-46a4-abb2-12039b78456a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc80dcd8-7d2b-46a4-abb2-12039b78456a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc80dcd8-7d2b-46a4-abb2-12039b78456a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6572cd6e-dbf1-4e5a-b8eb-402d57c9e006\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6572cd6e-dbf1-4e5a-b8eb-402d57c9e006')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6572cd6e-dbf1-4e5a-b8eb-402d57c9e006 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"english_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"N _ one\\n\",\n          \"Scope\\n\",\n          \"Hide process para _ meters\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hindi_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\u0915\\u0941\\u091b\\u0928\\u0939\\u0940\\u0902 (_ o) \\n\",\n          \"\\u0918\\u0930\\n\",\n          \"\\u091b\\u0941\\u092a\\u093e\\u090f\\u0901 process \\u0905\\u0928\\u0941\\u091a\\u094d\\u091b\\u0947\\u0926 \\u092e\\u0940\\u091f\\u0930\\u094d\\u0938\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling the encoding issue by removing the rows.\n",
        "def is_hindi_corrupted(text):\n",
        "    if re.search(r'[^\\u0900-\\u097F\\s,.?!-]', text):\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "CLMBsn9M_Bo0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the 'Hindi' column to create a mask\n",
        "df['Corrupted'] = df['hindi_txt'].apply(is_hindi_corrupted)\n",
        "\n",
        "# Filter out corrupted rows\n",
        "df_clean = df[~df['Corrupted']]\n",
        "\n",
        "# Drop the 'Corrupted' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Corrupted'])"
      ],
      "metadata": {
        "id": "IzYiEZRnHg0E"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMKkHxG9Hspq",
        "outputId": "9ece5b8a-cd40-4e75-92fa-49cc7d9f815d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134454, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, language=\"english\"):\n",
        "    # Normalize unicode characters\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    # Convert to lowercase if the text is in English\n",
        "    if language == \"english\":\n",
        "        text = text.lower()\n",
        "    # Remove any English words present in Hindi text.\n",
        "    if language == \"hindi\":\n",
        "        text = re.sub('[a-zA-Z]', '', text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "-kq-NSH9yvuy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[\"english_txt\"] = df_clean[\"english_txt\"].apply(clean_text)\n",
        "df_clean[\"hindi_txt\"] = df_clean['hindi_txt'].apply(clean_text, args=(\"hindi\",))"
      ],
      "metadata": {
        "id": "h-uvkUye8g8o"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "nKFtG_obLh84",
        "outputId": "65505976-9c24-44ff-a630-31f5514c4f47"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              english_txt  \\\n",
              "47370                start a slideshow view of the images   \n",
              "224830                                              false   \n",
              "135666                      temperature tone color picker   \n",
              "10750                                                type   \n",
              "38843   whether to play a sound when logging out of a ...   \n",
              "65903                             error expunging message   \n",
              "151089                                              xlyap   \n",
              "108783                        export in asynchronous mode   \n",
              "14159                                      save all files   \n",
              "232121  o believers if you follow the path shown by go...   \n",
              "\n",
              "                                                hindi_txt  \n",
              "47370                              छव क सलइड श दशय आरभ कर  \n",
              "224830                                                गलत  \n",
              "135666                                   तपकरम टन रग चयनक  \n",
              "10750                                                 कसम  \n",
              "38843                      कय सजल म लग ऑफ क दरन धवन बजन ह  \n",
              "65903                                    सनदश क हटन म तरट  \n",
              "151089                                             एकसलयप  \n",
              "108783                                 अतलयकलक सथत म नरयत  \n",
              "14159                                          सभ फइल सहज  \n",
              "232121  ऐ ईमन लनवल यद तम अललह क डर रखग त वह तमह एक वशष...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94483ad8-b2b6-4c14-880a-d52c575850fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_txt</th>\n",
              "      <th>hindi_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47370</th>\n",
              "      <td>start a slideshow view of the images</td>\n",
              "      <td>छव क सलइड श दशय आरभ कर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224830</th>\n",
              "      <td>false</td>\n",
              "      <td>गलत</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135666</th>\n",
              "      <td>temperature tone color picker</td>\n",
              "      <td>तपकरम टन रग चयनक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10750</th>\n",
              "      <td>type</td>\n",
              "      <td>कसम</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38843</th>\n",
              "      <td>whether to play a sound when logging out of a ...</td>\n",
              "      <td>कय सजल म लग ऑफ क दरन धवन बजन ह</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65903</th>\n",
              "      <td>error expunging message</td>\n",
              "      <td>सनदश क हटन म तरट</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151089</th>\n",
              "      <td>xlyap</td>\n",
              "      <td>एकसलयप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108783</th>\n",
              "      <td>export in asynchronous mode</td>\n",
              "      <td>अतलयकलक सथत म नरयत</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14159</th>\n",
              "      <td>save all files</td>\n",
              "      <td>सभ फइल सहज</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232121</th>\n",
              "      <td>o believers if you follow the path shown by go...</td>\n",
              "      <td>ऐ ईमन लनवल यद तम अललह क डर रखग त वह तमह एक वशष...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94483ad8-b2b6-4c14-880a-d52c575850fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94483ad8-b2b6-4c14-880a-d52c575850fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94483ad8-b2b6-4c14-880a-d52c575850fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-255bc94e-1df0-4c74-8d72-41f2e231a618\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-255bc94e-1df0-4c74-8d72-41f2e231a618')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-255bc94e-1df0-4c74-8d72-41f2e231a618 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_clean\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"english_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"save all files\",\n          \"false\",\n          \"error expunging message\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hindi_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u0938\\u092d \\u092b\\u0907\\u0932 \\u0938\\u0939\\u091c\",\n          \"\\u0917\\u0932\\u0924\",\n          \"\\u0938\\u0928\\u0926\\u0936 \\u0915 \\u0939\\u091f\\u0928 \\u092e \\u0924\\u0930\\u091f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean['English_Words'] = df_clean['english_txt'].apply(lambda x: len(x.split()))\n",
        "df_clean['Hindi_Words'] = df_clean['hindi_txt'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "5-j5YrNJLxid"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate averages\n",
        "average_english_words = df_clean['English_Words'].quantile(.99)\n",
        "average_hindi_words = df_clean['Hindi_Words'].quantile(.99)\n",
        "\n",
        "# Data for plotting\n",
        "averages = [average_english_words, average_hindi_words]\n",
        "languages = ['English', 'Hindi']\n",
        "\n",
        "# Creating the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(languages, averages, color=['blue', 'red'])\n",
        "plt.xlabel('Language')\n",
        "plt.ylabel('Number of Words per Sentence')\n",
        "plt.title('Comparison of Number of Words Counts in English and Hindi')\n",
        "plt.ylim(0, max(averages) + 1)  # Adjust y-axis for better visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NpOd55hIL7DA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torchtext\n",
        "Torchtext is a library within the PyTorch ecosystem designed to facilitate the preprocessing of textual data.\n",
        "\n",
        "## get_tokenizer\n",
        ". The get_tokenizer function is one of the core utilities provided by torchtext for tokenizing text data.\n",
        "\n",
        ". get_tokenizer retrieves a tokenizer function based on the method specified. This tokenizer can then be used to convert strings of text into lists of tokens.\n",
        "##Parameters\n",
        "  \n",
        "  tokenizer: This argument specifies the type of tokenizer to use. You can specify built-in tokenizers such as \"basic_english\", \"spacy\", \"moses\", or even provide a custom tokenizer function.\n",
        "\n",
        "  language: Some tokenizers, like those based on the Moses or Spacy libraries, might require you to specify the language of the text, which influences how the text is tokenized (e.g., handling language-specific punctuation and splitting rules)."
      ],
      "metadata": {
        "id": "UIFPGpu36sSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_eng = get_tokenizer('basic_english')\n",
        "tokenizer_hin = indic_tokenize.trivial_tokenize  # This is the Hindi tokenizer from Indic NLP\n",
        "\n",
        "tokenized_english_txt = [tokenizer_eng(english_sen) for english_sen in df_clean['english_txt'] ]\n",
        "tokenized_hindi_txt = [tokenizer_hin(hindi_sen) for hindi_sen in df_clean['hindi_txt'] ]"
      ],
      "metadata": {
        "id": "SzBeCo8MOcwE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_english_txt[7])\n",
        "print(tokenized_hindi_txt[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khwzrttoOFjp",
        "outputId": "aa9005fc-99fe-4f17-f51b-18a023d03f64"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['name', 'of', 'the', 'value', 'to', 'watch']\n",
            "['नम', 'क', 'मन', 'क']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build_vocab_from_iterator\n",
        "`build_vocab_from_iterator` function in the torchtext.vocab module is used to create a vocabulary from an iterable of tokenized data. This vocabulary is essential for converting textual data into numerical form.\n",
        "\n",
        "#Parameters:\n",
        "##tokenized_conv (iterator):\n",
        "This is the main data input to the function. It should be an iterator (like a `generator` or a `list`) that yields sequences of tokens. Each sequence represents a document or an example in your dataset.\n",
        "##min_freq (int, optional):\n",
        " This parameter specifies the minimum frequency a token must have to be included in the vocabulary. Tokens that appear fewer than min_freq times are excluded from the vocabulary. This is useful for removing rare words which might be typos or irrelevant to most analyses.\n",
        "##specials (list of str, optional):\n",
        " This is a list of special tokens that you want to add to the vocabulary. Common special tokens include:\n",
        "'<pad>': A padding token used to equalize the lengths of sequences.\n",
        "'<oov>' (or '<unk>' for \"unknown\"): A token used to represent out-of-vocabulary words during inference, or when a word appears that is not in the training vocabulary.\n",
        "##special_first (bool, optional):\n",
        " Determines the ordering of special tokens in the vocabulary. If True, special tokens are added at the beginning of the vocabulary. This can be helpful for certain models where token indices are significant (e.g., models using embedding layers might have specific handling for lower indices)."
      ],
      "metadata": {
        "id": "h4TytNjp6xKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# Step 3: Building Vocabulary\n",
        "features_vocab = build_vocab_from_iterator(tokenized_english_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "target_vocab = build_vocab_from_iterator(tokenized_hindi_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "features_vocab.set_default_index(features_vocab['<unk>'])\n",
        "target_vocab.set_default_index(target_vocab['<unk>'])"
      ],
      "metadata": {
        "id": "upBTp-UJS9xC"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)"
      ],
      "metadata": {
        "id": "CkkIj_XFLjWw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_vocab_total_words)  #English\n",
        "print(target_vocab_total_words)    #Hindi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5bIQHZuJXMS",
        "outputId": "ba9be79b-d045-4972-f51c-e1f6f1b535d4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16558\n",
            "13587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_vocab['<bos>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttQaYjVnpOh1",
        "outputId": "28bd0f2b-2151-4e36-c15e-b6a166994e84"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_vocab_total_words)\n",
        "print(target_vocab_total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnTdkafdLmNO",
        "outputId": "fc1f93c5-e6fc-48d5-8038-78b69318ae9f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16558\n",
            "13587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_indices(tokenized_texts, vocab):\n",
        "    indices_texts = []\n",
        "    for sentence in tokenized_texts:\n",
        "        indices_texts.append([vocab[token] for token in sentence if token in vocab])\n",
        "    return indices_texts"
      ],
      "metadata": {
        "id": "uvUtpWeDLt_g"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_indices = tokens_to_indices(tokenized_english_txt, features_vocab)\n",
        "hindi_indices = tokens_to_indices(tokenized_hindi_txt, target_vocab)"
      ],
      "metadata": {
        "id": "t1pH9g5XM-Nf"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_indices[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZMYCBAxJ-aB",
        "outputId": "9328a8e4-b88e-4350-9809-43c9c1fb2781"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[330, 17, 13, 4, 138],\n",
              " [71, 3167, 3513, 667, 17],\n",
              " [138, 53, 2190, 31, 6, 1747],\n",
              " [58, 4, 138, 53, 2190, 31, 1747],\n",
              " [593, 5, 1032]]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, english_data, hindi_data):\n",
        "        self.english_data = english_data\n",
        "        self.hindi_data = hindi_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        english = torch.tensor(self.english_data[idx], dtype=torch.long)\n",
        "        hindi = torch.tensor(self.hindi_data[idx], dtype=torch.long)\n",
        "        return english, hindi\n",
        "\n",
        "# Create the custom dataset\n",
        "dataset = TranslationDataset(english_indices, hindi_indices)\n",
        "FIXED_LENGTH = 60  # or any appropriate length based on your data or model requirements\n"
      ],
      "metadata": {
        "id": "Ohf0O1CnM-Qf"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Purpose of collate_fn\n",
        "The primary purpose of `collate_fn` is to dynamically decide how to combine multiple data samples into a single batch. Data samples can be anything from images, texts, or other forms of data, and they might not naturally fit together in a straightforward way (e.g., texts of varying lengths)."
      ],
      "metadata": {
        "id": "TP8Dy_V67dyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    english_batch, hindi_batch = zip(*batch)\n",
        "\n",
        "    # Pad or truncate English batch\n",
        "    english_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), features_vocab['<pad>'], dtype=torch.long)]) for seq in english_batch]\n",
        "\n",
        "    # Pad or truncate Hindi batch\n",
        "    hindi_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), target_vocab['<pad>'], dtype=torch.long)]) for seq in hindi_batch]\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    english_batch = torch.stack(english_batch)\n",
        "    hindi_batch = torch.stack(hindi_batch)\n",
        "\n",
        "    return english_batch, hindi_batch\n"
      ],
      "metadata": {
        "id": "KBEn7e-NcxkF"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  # Adjust the batch size as needed\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "TDhltO-xc1zM"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bs67MOd8achu"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wytwBPlbV0Sk",
        "outputId": "55f51ffd-d003-4983-fa98-71dbe525f631"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7ndzj28Siv",
        "outputId": "b8473c62-a19e-4461-9441-4b2ce34d2159"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-105-6d92b6dff899>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  english_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), features_vocab['<pad>'], dtype=torch.long)]) for seq in english_batch]\n",
            "<ipython-input-105-6d92b6dff899>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  hindi_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), target_vocab['<pad>'], dtype=torch.long)]) for seq in hindi_batch]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMf18HtM8X0q",
        "outputId": "bd5f689f-9434-4ddb-c5f1-3175a15e2179"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_itos`: stands for \"index-to-string\". The method returns a list where the indices in the list correspond to the numerical indices used in your model, and the values at those indices are the actual string representations (tokens)."
      ],
      "metadata": {
        "id": "MFD66slv7OYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):    #[4,8,9,15,12]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "aUv5MU5RM-UG"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)   # Transform for query\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)   # Transform for keys\n",
        "        self.Va = nn.Linear(hidden_size, 1)   # Compute the attention score\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # Expand query to match keys' batch and sequence dimension\n",
        "        # Encoder Output i.e key Shape (batch, seq_len, hidden_dim) when batch_first = True\n",
        "        # Hidden State of Decoder i.e query shape (num_dir*num_layers, batch, hidden_dim)\n",
        "\n",
        "        # Since Decoder Queries about the information to encoder on which token to focus when generating the current token\n",
        "        # we need to replecate the decoder Hidden State along the encoder output to get score for each output.\n",
        "        key_shape = keys.size()\n",
        "\n",
        "        query = query.repeat(1, key_shape[1], 1)\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))  # attn_score = VT.(tanh(Wa*s|encoder + Ua|decoder + bias))\n",
        "        scores = scores.squeeze(-1)\n",
        "\n",
        "        weights = torch.softmax(scores, dim=1)\n",
        "        weights = weights.unsqueeze(1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        bos_token_index = features_vocab['<bos>']\n",
        "        decoder_input = torch.full((batch_size, 1), bos_token_index, dtype=torch.long, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "        # fixed length set to 60\n",
        "        for i in range(60):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)    # this is the shape of [num_layers * num_directions, batch_size, hidden_size]\n",
        "                                            # encoder output [batch_size, seq_len, hidden_size]\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "SOZQffs_aOrQ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "I53ihZ7Jfiab"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained weights\n",
        "encoder_path = \"/content/encoder_epoch_30.pth\"\n",
        "decoder_path = \"/content/decoder_epoch_30.pth\"\n",
        "encoder.load_state_dict(torch.load(encoder_path))\n",
        "decoder.load_state_dict(torch.load(decoder_path))\n",
        "\n",
        "# Define training function with additional arguments for loading weights\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "          print_every=5, plot_every=5, save_every=5, save_path=\"./\", load_weights=False):\n",
        "\n",
        "    if load_weights:\n",
        "        encoder.load_state_dict(torch.load(encoder_path))\n",
        "        decoder.load_state_dict(torch.load(decoder_path))\n",
        "        print(\"Loaded pre-trained weights from epoch 30.\")\n",
        "\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(31, n_epochs + 31):  # Start from epoch 31 (after loaded weights)\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, (epoch - 30) / n_epochs),\n",
        "                                        epoch, (epoch - 30) / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            encoder_save_path = os.path.join(save_path, f'encoder_epoch_{epoch}.pth')\n",
        "            decoder_save_path = os.path.join(save_path, f'decoder_epoch_{epoch}.pth')\n",
        "            torch.save(encoder.state_dict(), encoder_save_path)\n",
        "            torch.save(decoder.state_dict(), decoder_save_path)\n",
        "            print(f'Model saved at epoch {epoch}')\n",
        "\n",
        "    showPlot(plot_losses)\n"
      ],
      "metadata": {
        "id": "uHBcirVDfidT"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "rzuTOQJ8ffI4"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "E96KOEbPfW1T"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)\n",
        "\n",
        "encoder = EncoderRNN(features_vocab_total_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, target_vocab_total_words).to(device)"
      ],
      "metadata": {
        "id": "E3J8fUnzfiHK"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for additional 20 epochs, loading pre-trained weights\n",
        "train(train_dataloader, encoder, decoder, n_epochs=25, print_every=5, plot_every=5, load_weights=True)"
      ],
      "metadata": {
        "id": "kNAVKmc3jxWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WFNozta2sdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, feature_vocab, target_vocab):\n",
        "    with torch.no_grad():\n",
        "        tokenized_english_txt_test = tokenizer_eng(sentence)\n",
        "        print(f\"Tokenized sentence: {tokenized_english_txt_test}\")\n",
        "\n",
        "        english_indices_test = tokens_to_indices([tokenized_english_txt_test], features_vocab)[0]\n",
        "        print(f\"Indices: {english_indices_test}\")\n",
        "\n",
        "        # Ensure we have exactly 60 tokens (FIXED_LENGTH)\n",
        "        if len(english_indices_test) < FIXED_LENGTH:\n",
        "            english_indices_test += [features_vocab['<pad>']] * (FIXED_LENGTH - len(english_indices_test))\n",
        "        elif len(english_indices_test) > FIXED_LENGTH:\n",
        "            english_indices_test = english_indices_test[:FIXED_LENGTH]\n",
        "\n",
        "        print(f\"Padded/Truncated indices: {english_indices_test}\")\n",
        "\n",
        "        try:\n",
        "            input_tensor = torch.LongTensor(english_indices_test).to(device).unsqueeze(0)\n",
        "            print(f\"Input tensor shape: {input_tensor.shape}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating input tensor: {e}\")\n",
        "            return [], None\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "        print(f\"Decoded ids shape: {decoded_ids.shape}\")\n",
        "\n",
        "        EOS_token = feature_vocab['<eos>']\n",
        "        decoded_words = []\n",
        "\n",
        "        # Handle both 1D and 0D tensors\n",
        "        if decoded_ids.dim() == 0:\n",
        "            decoded_ids = decoded_ids.unsqueeze(0)\n",
        "\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<eos>')\n",
        "                break\n",
        "            decoded_words.append(target_vocab.get_itos()[idx.item()] if idx.item() < len(target_vocab) else '<unk>')\n",
        "\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "# Ensure <pad> token is in the vocabulary\n",
        "if '<pad>' not in features_vocab:\n",
        "    features_vocab['<pad>'] = len(features_vocab)\n",
        "\n",
        "# Try evaluation again\n",
        "sentence = \"here is my pet.\"\n",
        "decoder_output, attn_weights = evaluate(encoder, decoder, sentence, features_vocab, target_vocab)\n",
        "if decoder_output:\n",
        "    print(\"Translation: \" + \" \".join(decoder_output))\n",
        "else:\n",
        "    print(\"Evaluation failed. Check the printed debug information.\")"
      ],
      "metadata": {
        "id": "RBihHux53ta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def indices_to_words(indices, vocab):\n",
        "#     return [vocab.get_itos()[index] if index < len(vocab) else '<unk>' for index in indices]"
      ],
      "metadata": {
        "id": "vUQNMln-zNaK"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}